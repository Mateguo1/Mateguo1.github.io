---
layout: post
title: Graph Convolutional Networks
description: GCN
keywords: Neural Networks
---

# Graph Convolutional Networks

## 1、Graph Neural Networks, GNN:

先来简单解释一下图神经网络，主要流程就是：**聚合、更新、循环**。

首先讲解下**聚合**，可以看到下图的图结构中一共包含A、B、C、D、E、F六个点，而点与点之间的连线就代表着这两点之间有某种联系，而每个点右下角的(X,X,X,X)用于表示该点的特征，这个特征可以是提取到的或者是标签，也可以是初始化的，这里其实把现在图上的特征说成**初始特征**，更利于后面内容的区分和理解。

![image-20210602190239441](/assets/img/GNN_1.png)

接下来，假设我们要对A进行分类，这就需要得到它的特征，而A的特征由两部分组成：自身+邻居信息。这里简单解释下为什么邻居信息会组成A的特征，介于上面提到的点与点之间有连线，说明这俩点之间有某种关系，所以说如果对A进行分类/定义，某种程度上而言，它的邻居B、C、D的特征也具有一定的参考价值，然后再用一句话来解释一下，就可以很明白的理解了，“近朱者赤，近墨者黑”。

最后可以把邻居信息N，用公式表示为，N = a\*(2,2,2,2) + b\*(3,3,3,3) + c\*(3,3,3,3)，其中的a、b、c大概就是超参数，可以进行优化、改进。

然后就到了**更新**的阶段，将更新后A的信息用公式表示为 A_new =  σ(W((1,1,1,1))+σ*N)，其中的σ表示激活函数，W( )为模型训练的参数。

然后再来说下GNN层数的一个点，让我们把目光重新放回到上面的那张图中和点A相连的点有B、C、D，也就是说A包含B、C、D的信息，所以我们就可以知道，而B包含A、C的信息，C包含A、B、E的信息，D包含A、F的信息。那么在第二层，也就是第二次聚合时，聚合A的信息，现在A已经包含了C的信息，而C中又包含了E的信息，所以A也就会获得E的特征，然后就可以得到每一个结点的最终特征，然后就可以进行结点分类或者关联预测了。





