---
layout: post
title: ResNet
categories: Computer Version
description: ResNet
keywords: ResNet，classification
---

# ResNet

今天简单看了一下ResNet，然后做一下笔记吧。

传统的网络过深，可能出现梯度爆炸、消失，退化问题，下面是ResNet网络的两个亮点，也是主要的笔记内容：
（1）提出Residual结构，使得可以搭建超深的网络结构（可以解决退化问题）
（2）使用Batch Normalization加速训练（dropout，可以解决梯度爆炸、消失）

梯度爆炸、消失如下所示：

![image-20200724194650066](/assets/img/image-20200724194650066.png)

## Residual：

残差结构

#### 1、整体结构

下图中左边的残差结构适用于层数较少的网络（如：ResNet18、ResNet34），右边适用于层数较多的网络（如：ResNet101、ResNet152）。

![image-20200724194327470](/assets/img/image-20200724194327470.png)

至于为什么深层网络要使用右边的残差结构，简单计算一下二者的参数数目（保证输出相同）
左：3×3×256×256+3×3×256×256=1,179,648<br>
右：1×1×256×64+3×3×64×64+1×1×64×256=69,632
可以明显看出右边结构的参数数目要远少于左边结构的，因此采用右边结构。

然后来解释一下，残差结构的各部分的含义，首先**直线部分**就是**正常卷积等一系列操作**，然后**曲线部分**就是 **shortcut/捷径分支**，然后最终将直线部分和捷径分支输出相加（要保证两个输出特征矩阵 shape 相同）

下图是ResNet34的整体结构：

![image-20200724200521083](/assets/img/image-20200724200521083.png)

![image-20200724194327470](/assets/img/image-20200724194327470.png)

#### 2、左边结构详解：

可以看到上面整体结构图中残差块中曲线部分会有**<font color="red">实线</font>**和**<font color="red">虚线</font>**之分，接下来分别详细讲一下

##### （1）实线：

卷积的 步长Stride 均为 1 ，从而保证了整体形状是不变的

##### （2）虚线：

虚线的残差结构就是起到了**降维**的作用，然后是在**直线部分的第一个卷积 步长Stride 为2**，其余均为 1 ，**曲线部分卷积 步长Stride 为2**，从而保证两者输出shape相同。

#### 3、右边结构详解：

实线、虚线的区别基本和上面是相同的，注意Stride在哪个卷积里变化的即可，然后是说明一下：

conv1：可以看到是 1×1 并且channel维度和输入不同，是用来压缩channel的<br>
conv2：正常的 3×3 卷积层<br>
conv3：可以看到也是 1×1 是用于还原channel的，这是为了保证和shortcut输出的维度相同

#### 4、汇总、注意：

下图是原论文中给出的不同深度的ResNet网络结构配置，其中的 ×N 表示将这个残差结构重复N次：

![image-20200724201909926](/assets/img/image-20200724201909926.png)

然后注意这里面所有的网络结构的 conv3_x、conv4_x、conv5_x，对应的一系列残差结构中的第一层都是虚线残差结构，这是为了调整 shape（**输出特征矩阵宽和高均为输入的一半，然后 channel 调整为下一层所需的 channel**）。

但是对于 ResNet50/101/152，其中的 conv2_x 对应一系列残差结构的第一层也是虚线残差结构，因为需要调整输入特征矩阵的channel，通过表格知道经过 3×3 的max pooling 之后输出的特征矩阵结构为 [56,56,64]，但是 conv2_x 期望的输入特征矩阵结构为 [56,56,256]，这里还是为了保证**直线、曲线的输出相同**，但是这里只需要调整 channel 即可，并不需要想上面的调整宽高。

