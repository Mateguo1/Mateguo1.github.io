---
layout: post
title: SOFT
description: deep-learning
categories: Neural_Network
keywords: deep-learning
---

# SOFT：

<a href="https://blog.csdn.net/qq_43923588/article/details/122450628">论文笔记</a>

低秩矩阵分解算法

Newton-Raphson 方法来计算 Moore-Penrose逆矩阵

Hadamard product大概就是矩阵乘法？得到矩阵，和点积、点乘之间的关系、区别参考：<a href="https://blog.csdn.net/qq_33148001/article/details/104804897?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-104804897-blog-122090386.pc_relevant_antiscanv3&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-104804897-blog-122090386.pc_relevant_antiscanv3&utm_relevant_index=1">博客1</a>，<a href="https://blog.csdn.net/weixin_45169380/article/details/122090386">博客2</a>
高斯核函数

半正定矩阵、正定矩阵，<a href="https://blog.csdn.net/weixin_45169380/article/details/122090386">博客2</a>
分块矩阵：<a href="https://blog.csdn.net/hpdlzu80100/article/details/99663452">博客1</a>，<a href="https://zhuanlan.zhihu.com/p/44860862">博客2</a>

nystrom：<a href="https://spaces.ac.cn/archives/8180">不知道算不算是SOFT的另外一种思路</a>，这个方法暂时没找到，Gram 矩阵（风格转换中常用）

<a href="https://zhuanlan.zhihu.com/p/410258597">一篇很好的解释Transformer的博客</a>，<a href="https://blog.csdn.net/longxinchen_ml/article/details/86533005">另外一篇很好的解释Transformer的博客</a>，

<a href="https://zhuanlan.zhihu.com/p/445122996">一篇很好的解释ViT的博客</a>

